{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1e8e7c-1421-40bc-97bd-fec4f3ac5193",
   "metadata": {
    "id": "3c1e8e7c-1421-40bc-97bd-fec4f3ac5193",
    "outputId": "8cf8ccf9-1eb5-4ba7-e4e1-d807f376ecad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers peft accelerate datasets -q\n",
    "!pip install trl -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ac5580-608b-4dac-a585-8371d3227afa",
   "metadata": {
    "id": "d1ac5580-608b-4dac-a585-8371d3227afa"
   },
   "source": [
    "Load Base Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4062e53f-5539-4626-98f3-6108faeebe12",
   "metadata": {
    "id": "4062e53f-5539-4626-98f3-6108faeebe12",
    "outputId": "4b77dccb-d22e-44b9-b419-9ab79e328425"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a761239f-7ad0-4d9e-998a-ebeedd4bfda2",
   "metadata": {
    "id": "a761239f-7ad0-4d9e-998a-ebeedd4bfda2",
    "outputId": "9896178a-0a00-4ab8-a32b-03e8edfacbc3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Hugging Face token:  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\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "token = input(\"Enter your Hugging Face token: \")\n",
    "login(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc4a717-7fd8-40d4-ada0-abbb6f71762d",
   "metadata": {
    "id": "adc4a717-7fd8-40d4-ada0-abbb6f71762d",
    "outputId": "c2c5e5e9-6f18-48d3-8041-42ae56a64f13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.ubuntu.com/ubuntu focal-security InRelease [128 kB]\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease   \u001B[0m\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease [128 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease [128 kB][33m\u001B[33m\u001B[33m\u001B[33m\n",
      "Fetched 383 kB in 1s (285 kB/s)  \u001B[0m\u001B[33m\u001B[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "46 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "build-essential is already the newest version (12.8ubuntu1.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n",
      "/usr/bin/gcc\n",
      "gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "Copyright (C) 2019 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!apt update\n",
    "!apt install build-essential -y\n",
    "\n",
    "!which gcc\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e52211-fe9a-4e20-928f-783b9b97100a",
   "metadata": {
    "id": "29e52211-fe9a-4e20-928f-783b9b97100a",
    "outputId": "5fedd849-6e6d-46ab-dc31-91da75a4c9c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.56s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "BASE_MODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "DATASET_ID = \"b-mc2/sql-create-context\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_ID, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL_ID, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bf568f-83b5-4d11-9252-f5927fe7b7ab",
   "metadata": {
    "id": "a4bf568f-83b5-4d11-9252-f5927fe7b7ab"
   },
   "source": [
    "Apply LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead51294-9387-4e65-8945-1baadf7bd306",
   "metadata": {
    "id": "ead51294-9387-4e65-8945-1baadf7bd306",
    "outputId": "460f5877-e146-47ac-d8e8-8ec5db2952f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor name, module in model.named_modules():\\n    if \"proj\" in name:\\n        print(name)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for name, module in model.named_modules():\n",
    "    if \"proj\" in name:\n",
    "        print(name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee685f9f-6212-4fae-a863-7f1355fe2421",
   "metadata": {
    "id": "ee685f9f-6212-4fae-a863-7f1355fe2421",
    "outputId": "c99f93bc-8b91-4421-bf67-87b04b7eadc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ldd (Ubuntu GLIBC 2.31-0ubuntu9.12) 2.31\n",
      "Copyright (C) 2020 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "Written by Roland McGrath and Ulrich Drepper.\n"
     ]
    }
   ],
   "source": [
    "!ldd --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cacc802-3f4b-4b48-ae01-482f3f833409",
   "metadata": {
    "id": "0cacc802-3f4b-4b48-ae01-482f3f833409",
    "outputId": "39359096-fc19-46c2-a608-21b98460214e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes==0.41.1\n",
      "  Downloading bitsandbytes-0.41.1-py3-none-any.whl.metadata (9.8 kB)\n",
      "Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m92.6/92.6 MB\u001B[0m \u001B[31m33.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: bitsandbytes\n",
      "  Attempting uninstall: bitsandbytes\n",
      "    Found existing installation: bitsandbytes 0.45.5\n",
      "    Uninstalling bitsandbytes-0.45.5:\n",
      "      Successfully uninstalled bitsandbytes-0.45.5\n",
      "Successfully installed bitsandbytes-0.41.1\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes==0.41.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95c2357-e9c0-4c0d-addd-c38510c6fe16",
   "metadata": {
    "id": "d95c2357-e9c0-4c0d-addd-c38510c6fe16"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117e968c-8fd4-4537-85e2-283bc11a7f67",
   "metadata": {
    "id": "117e968c-8fd4-4537-85e2-283bc11a7f67"
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.gradient_checkpointing_disable()\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ec5f9d-0c99-4100-af64-550723515c3d",
   "metadata": {
    "id": "05ec5f9d-0c99-4100-af64-550723515c3d"
   },
   "source": [
    "Load and Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f45a5e-25f4-4556-8fc7-197e73a86d22",
   "metadata": {
    "id": "02f45a5e-25f4-4556-8fc7-197e73a86d22",
    "outputId": "c96ead8f-bf23-40de-fc45-87c3cf8c10cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 7858/7858 [00:01<00:00, 5697.62 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 62861\n",
      "Validation dataset size: 7858\n",
      "Test dataset size: 7858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = load_dataset(DATASET_ID)\n",
    "\n",
    "train_testvalid = dataset['train'].train_test_split(test_size=0.2, seed=42) # Split into 80% train, 20% for test/validation\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5, seed=42) # Split the 20% into 10% test, 10% validation\n",
    "\n",
    "train_dataset = train_testvalid['train']\n",
    "val_dataset = test_valid['train']\n",
    "test_dataset = test_valid['test']\n",
    "\n",
    "def preprocess(batch):\n",
    "    texts = [\n",
    "        f\"-- Context: {c}\\\\n-- Question: {q}\\\\n-- SQL: {a}\"\n",
    "        for c, q, a in zip(batch[\"context\"], batch[\"question\"], batch[\"answer\"])\n",
    "    ]\n",
    "    tokenized = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=512)\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess, batched=True, remove_columns=train_dataset.column_names)\n",
    "val_dataset = val_dataset.map(preprocess, batched=True, remove_columns=val_dataset.column_names)\n",
    "test_dataset = test_dataset.map(preprocess, batched=True, remove_columns=test_dataset.column_names)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acf5303-1a78-4cba-a1d7-334a4c494084",
   "metadata": {
    "id": "1acf5303-1a78-4cba-a1d7-334a4c494084",
    "outputId": "56935f0f-6f3c-4093-a827-3b90decfd455"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['answer', 'question', 'context']\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"].column_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eef46c4-f100-468b-b7f0-96fd2ce90275",
   "metadata": {
    "id": "0eef46c4-f100-468b-b7f0-96fd2ce90275"
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c5b1bd-d4ae-458e-8a2f-323521f67305",
   "metadata": {
    "id": "24c5b1bd-d4ae-458e-8a2f-323521f67305",
    "outputId": "3128d939-4f1a-450d-9e14-2abb56960198"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e1cc4c-8267-4ce9-8277-8961876a0e97",
   "metadata": {
    "id": "c0e1cc4c-8267-4ce9-8277-8961876a0e97",
    "outputId": "2acc0569-13ec-449a-fb9d-3191461cc4bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.51.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(f\"Transformers version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe97a79-1f39-4eec-924c-7cf39290ef63",
   "metadata": {
    "id": "7fe97a79-1f39-4eec-924c-7cf39290ef63",
    "outputId": "3e46ac3f-d4a1-4894-f0b1-c4c0cd54610f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting class: <class 'transformers.training_args.TrainingArguments'>\n",
      "   From module: transformers.training_args\n",
      "   Source file claimed by Python: /opt/conda/lib/python3.10/site-packages/transformers/training_args.py\n",
      "\n",
      "Arguments of TrainingArguments.__init__ according to 'inspect':\n",
      "['self', 'output_dir', 'overwrite_output_dir', 'do_train', 'do_eval', 'do_predict', 'eval_strategy', 'prediction_loss_only', 'per_device_train_batch_size', 'per_device_eval_batch_size', 'per_gpu_train_batch_size', 'per_gpu_eval_batch_size', 'gradient_accumulation_steps', 'eval_accumulation_steps', 'eval_delay', 'torch_empty_cache_steps', 'learning_rate', 'weight_decay', 'adam_beta1', 'adam_beta2', 'adam_epsilon', 'max_grad_norm', 'num_train_epochs', 'max_steps', 'lr_scheduler_type', 'lr_scheduler_kwargs', 'warmup_ratio', 'warmup_steps', 'log_level', 'log_level_replica', 'log_on_each_node', 'logging_dir', 'logging_strategy', 'logging_first_step', 'logging_steps', 'logging_nan_inf_filter', 'save_strategy', 'save_steps', 'save_total_limit', 'save_safetensors', 'save_on_each_node', 'save_only_model', 'restore_callback_states_from_checkpoint', 'no_cuda', 'use_cpu', 'use_mps_device', 'seed', 'data_seed', 'jit_mode_eval', 'use_ipex', 'bf16', 'fp16', 'fp16_opt_level', 'half_precision_backend', 'bf16_full_eval', 'fp16_full_eval', 'tf32', 'local_rank', 'ddp_backend', 'tpu_num_cores', 'tpu_metrics_debug', 'debug', 'dataloader_drop_last', 'eval_steps', 'dataloader_num_workers', 'dataloader_prefetch_factor', 'past_index', 'run_name', 'disable_tqdm', 'remove_unused_columns', 'label_names', 'load_best_model_at_end', 'metric_for_best_model', 'greater_is_better', 'ignore_data_skip', 'fsdp', 'fsdp_min_num_params', 'fsdp_config', 'tp_size', 'fsdp_transformer_layer_cls_to_wrap', 'accelerator_config', 'deepspeed', 'label_smoothing_factor', 'optim', 'optim_args', 'adafactor', 'group_by_length', 'length_column_name', 'report_to', 'ddp_find_unused_parameters', 'ddp_bucket_cap_mb', 'ddp_broadcast_buffers', 'dataloader_pin_memory', 'dataloader_persistent_workers', 'skip_memory_metrics', 'use_legacy_prediction_loop', 'push_to_hub', 'resume_from_checkpoint', 'hub_model_id', 'hub_strategy', 'hub_token', 'hub_private_repo', 'hub_always_push', 'gradient_checkpointing', 'gradient_checkpointing_kwargs', 'include_inputs_for_metrics', 'include_for_metrics', 'eval_do_concat_batches', 'fp16_backend', 'push_to_hub_model_id', 'push_to_hub_organization', 'push_to_hub_token', 'mp_parameters', 'auto_find_batch_size', 'full_determinism', 'torchdynamo', 'ray_scope', 'ddp_timeout', 'torch_compile', 'torch_compile_backend', 'torch_compile_mode', 'include_tokens_per_second', 'include_num_input_tokens_seen', 'neftune_noise_alpha', 'optim_target_modules', 'batch_eval_metrics', 'eval_on_start', 'use_liger_kernel', 'eval_use_gather_object', 'average_tokens_across_devices']\n",
      "\n",
      "CRITICAL ERROR: 'evaluation_strategy' IS NOT found in the __init__ arguments by inspect!\n",
      "This would mean the Python file content is outdated or incorrect.\n",
      "\n",
      "Attempting to read a few lines from the source file to check for 'evaluation_strategy':\n",
      "Found 'evaluation_strategy' on line 1329: evaluation_strategy: Union[IntervalStrategy, str] = field(\n",
      "Found 'evaluation_strategy' on line 1473: if self.evaluation_strategy is not None:\n",
      "Found 'evaluation_strategy' on line 1475: \"`evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\",\n",
      "Found 'evaluation_strategy' on line 1478: self.eval_strategy = self.evaluation_strategy\n",
      "\n",
      "Final re-attempt to initialize TrainingArguments:\n",
      "ERROR on final re-attempt: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import sys\n",
    "\n",
    "from transformers import TrainingArguments as ActualTrainingArguments\n",
    "\n",
    "print(f\"Inspecting class: {ActualTrainingArguments}\")\n",
    "print(f\"   From module: {ActualTrainingArguments.__module__}\")\n",
    "source_file_path = sys.modules[ActualTrainingArguments.__module__].__file__\n",
    "print(f\"   Source file claimed by Python: {source_file_path}\")\n",
    "\n",
    "print(\"\\nArguments of TrainingArguments.__init__ according to 'inspect':\")\n",
    "try:\n",
    "    init_spec = inspect.getfullargspec(ActualTrainingArguments.__init__)\n",
    "    print(init_spec.args)\n",
    "    if 'evaluation_strategy' in init_spec.args:\n",
    "        print(\"\\nSUCCESS: 'evaluation_strategy' IS found in the __init__ arguments by inspect!\")\n",
    "    else:\n",
    "        print(\"\\nCRITICAL ERROR: 'evaluation_strategy' IS NOT found in the __init__ arguments by inspect!\")\n",
    "        print(\"This would mean the Python file content is outdated or incorrect.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Could not inspect __init__ arguments: {e}\")\n",
    "\n",
    "print(\"\\nAttempting to read a few lines from the source file to check for 'evaluation_strategy':\")\n",
    "try:\n",
    "    with open(source_file_path, 'r', encoding='utf-8') as f:\n",
    "        lines_with_keyword = 0\n",
    "        found_in_init_signature = False\n",
    "        for i, line in enumerate(f):\n",
    "            if 'evaluation_strategy' in line:\n",
    "                print(f\"Found 'evaluation_strategy' on line {i+1}: {line.strip()}\")\n",
    "                lines_with_keyword += 1\n",
    "                if 'def __init__(' in line or (lines_with_keyword == 1 and 'evaluation_strategy: Optional[str] = None' in line.replace(\" \", \"\")):\n",
    "                    found_in_init_signature = True\n",
    "            if i > 2000 and lines_with_keyword > 0:\n",
    "                break\n",
    "            if i > 10000:\n",
    "                 print(\"Reached line limit for scanning.\")\n",
    "                 break\n",
    "        if lines_with_keyword == 0:\n",
    "            print(\"Could not find the string 'evaluation_strategy' anywhere in the beginning of the file.\")\n",
    "        elif found_in_init_signature:\n",
    "            print(\"Keyword 'evaluation_strategy' appears to be part of an __init__ signature or related dataclass field definition in the file.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Could not read or search the source file: {e}\")\n",
    "\n",
    "print(\"\\nFinal re-attempt to initialize TrainingArguments:\")\n",
    "try:\n",
    "    args = ActualTrainingArguments(\n",
    "        output_dir=\"./test_output_final_check\",\n",
    "        evaluation_strategy=\"steps\"\n",
    "    )\n",
    "    print(\"SUCCESS on final re-attempt!\")\n",
    "except TypeError as e:\n",
    "    print(f\"ERROR on final re-attempt: {e}\")\n",
    "except Exception as e_gen:\n",
    "    print(f\"DIFFERENT ERROR on final re-attempt: {e_gen}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa98bda-e862-4f35-8ca6-411fc3385b9b",
   "metadata": {
    "id": "3aa98bda-e862-4f35-8ca6-411fc3385b9b",
    "outputId": "bea8cfe1-0b5a-4388-ba5b-cb854861b99c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 20,971,520 || all params: 8,051,232,768 || trainable%: 0.2605\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight requires grad: True\n",
      "base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight requires grad: True\n",
      "base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight requires grad: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncating train dataset: 100%|██████████| 62861/62861 [00:00<00:00, 86921.62 examples/s]\n",
      "Truncating eval dataset: 100%|██████████| 7858/7858 [00:00<00:00, 64759.40 examples/s]\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 53:49:52, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.973100</td>\n",
       "      <td>0.966205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.893800</td>\n",
       "      <td>0.927207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=1.0175680494308472, metrics={'train_runtime': 193972.193, 'train_samples_per_second': 0.021, 'train_steps_per_second': 0.003, 'total_flos': 9.2478212407296e+16, 'train_loss': 1.0175680494308472})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./llama3-sql-lora\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    max_steps=500,\n",
    "    logging_steps=10,\n",
    "    logging_first_step=True,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=250,\n",
    "    save_total_limit=2,\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"none\",\n",
    "    logging_dir=\"./logs\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=250\n",
    ")\n",
    "\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name} requires grad: {param.requires_grad}\")\n",
    "\n",
    "model.train()\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset, # Use the new train_dataset\n",
    "    eval_dataset=val_dataset,   # Add the validation dataset\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9450974a-84fa-4b45-b428-5353718f0390",
   "metadata": {
    "id": "9450974a-84fa-4b45-b428-5353718f0390"
   },
   "source": [
    "Save Fine-Tuned LoRA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31d96f7-6654-4ea0-81a5-b2a655f4e3f2",
   "metadata": {
    "id": "c31d96f7-6654-4ea0-81a5-b2a655f4e3f2",
    "outputId": "72ca0ef7-8e96-4cac-ba43-975a053fc925"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 21.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged model and tokenizer to: ./llama3-sql-lora/final-merged\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "model_save_name = \"llama3-sql-lora\"\n",
    "checkpoint_number = 500\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=None\n",
    ")\n",
    "\n",
    "checkpoint_path = f\"./{model_save_name}/checkpoint-{checkpoint_number}\"\n",
    "peft_model = PeftModel.from_pretrained(base_model, checkpoint_path)\n",
    "\n",
    "with torch.no_grad():\n",
    "    merged_model = peft_model.merge_and_unload()\n",
    "\n",
    "save_path = f\"./{model_save_name}/final-merged\"\n",
    "merged_model.save_pretrained(save_path, safe_serialization=False)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "\n",
    "print(f\"Saved merged model and tokenizer to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601cb6dd-e176-4ff4-b39c-eb2c2d73ebb5",
   "metadata": {
    "id": "601cb6dd-e176-4ff4-b39c-eb2c2d73ebb5",
    "outputId": "946a08d7-f363-429d-d19a-c65447a10b2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./llama3-sql-lora/final/tokenizer_config.json',\n",
       " './llama3-sql-lora/final/special_tokens_map.json',\n",
       " './llama3-sql-lora/final/tokenizer.json')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.save_pretrained(\"./llama3-sql-lora/final\")\n",
    "#tokenizer.save_pretrained(\"./llama3-sql-lora/final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dd8b3e-864f-4a18-9f9b-49a784e4d03a",
   "metadata": {
    "id": "e1dd8b3e-864f-4a18-9f9b-49a784e4d03a",
    "outputId": "4491dfa6-20ec-4873-e386-5e1262b90361"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model files:\n",
      "['adapter_config.json', 'adapter_model.safetensors', 'README.md', 'special_tokens_map.json', 'tokenizer.json', 'tokenizer_config.json']\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "\n",
    "#model_path = \"./llama3-sql-lora/final\"\n",
    "\n",
    "#print(\"Model files:\")\n",
    "#print(os.listdir(model_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708cce85-2e89-4f9c-a07f-2f9e824ebf85",
   "metadata": {
    "id": "708cce85-2e89-4f9c-a07f-2f9e824ebf85"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26feaac3-44a6-4b81-a822-221f53daeea1",
   "metadata": {
    "id": "26feaac3-44a6-4b81-a822-221f53daeea1",
    "outputId": "864d99f2-c305-42b7-bdb4-9d6677b7ad4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation size: 1\n",
      "\n",
      "=== Loading Fine-Tuned LLaMA 3 Model ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 38.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading Base LLaMA 3 Model ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 117.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating Fine-Tuned Model ===\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT distance_duration FROM table_name_3 WHERE date = \"sept 5\" AND race_title = \"le grand prix de trois-rivières\" VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR\n",
      "\n",
      "Exact Matches: 1/1 (100.00%)\n",
      "Execution Accuracy: 1/1 (100.00%)\n",
      "\n",
      "Sample 1:\n",
      "Question: What is the distance/duration on sept 5 of le grand prix de trois-rivières?\n",
      "Schema: CREATE TABLE table_name_3 (distance_duration VARCHAR, date VARCHAR, race_title VARCHAR)\n",
      "Generated SQL: SELECT distance_duration FROM table_name_3 WHERE date = \"sept 5\" AND race_title = \"le grand prix de trois-rivières\"\n",
      "Gold SQL: SELECT distance_duration FROM table_name_3 WHERE date = \"sept 5\" AND race_title = \"le grand prix de trois-rivières\"\n",
      "Exact Match: True\n",
      "Execution Correct: True\n",
      "\n",
      "=== Evaluating Base Model ===\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT * FROM table_name_3 WHERE date ='sept 5' AND race_title = 'le grand prix de trois-rivières';  ###### 0.0005 sec 0.0000 sec 0.0005 sec ###### 1 row in set (0.00 sec)\n",
      "\n",
      "Exact Matches: 0/1 (0.00%)\n",
      "Execution Accuracy: 1/1 (100.00%)\n",
      "\n",
      "Sample 1:\n",
      "Question: What is the distance/duration on sept 5 of le grand prix de trois-rivières?\n",
      "Schema: CREATE TABLE table_name_3 (distance_duration VARCHAR, date VARCHAR, race_title VARCHAR)\n",
      "Generated SQL: SELECT * FROM table_name_3 WHERE date ='sept 5' AND race_title = 'le grand prix de trois-rivières'\n",
      "Gold SQL: SELECT distance_duration FROM table_name_3 WHERE date = \"sept 5\" AND race_title = \"le grand prix de trois-rivières\"\n",
      "Exact Match: False\n",
      "Execution Correct: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import re\n",
    "import sqlite3\n",
    "from datasets import load_dataset\n",
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "def extract_sql(text: str) -> str:\n",
    "    stop_tokens = [\"###\", \"Explanation\", \"View\", \"VARCHAR\"]\n",
    "\n",
    "    for token in stop_tokens:\n",
    "        if token in text:\n",
    "            text = text.split(token)[0]\n",
    "\n",
    "    code_block = re.search(r\"```(?:sql)?\\s*(SELECT .*?)```\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if code_block:\n",
    "        sql = code_block.group(1)\n",
    "    else:\n",
    "        example_block = re.search(r\"###\\s*Example:\\s*(SELECT .*?)(\\n|$)\", text, re.DOTALL | re.IGNORECASE)\n",
    "        if example_block:\n",
    "            sql = example_block.group(1)\n",
    "        else:\n",
    "            fallback = re.search(r\"(SELECT|INSERT|UPDATE|DELETE|CREATE|ALTER|DROP)\\b.*\", text, re.IGNORECASE | re.DOTALL)\n",
    "            sql = fallback.group(0) if fallback else text\n",
    "\n",
    "    sql = ' '.join(sql.strip().split())\n",
    "    return sql.rstrip(';')\n",
    "\n",
    "def setup_database(schema: str) -> sqlite3.Connection:\n",
    "    conn = sqlite3.connect(\":memory:\")\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.executescript(schema)\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        print(f\"DB setup error:\\n{schema}\\nError: {e}\")\n",
    "    return conn\n",
    "\n",
    "def execute_sql_query(conn: sqlite3.Connection, sql_query: str) -> List[Dict]:\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(sql_query)\n",
    "        return cursor.fetchall()\n",
    "    except Exception as e:\n",
    "        print(f\"Query execution error:\\n{sql_query}\\nError: {e}\")\n",
    "        return []\n",
    "\n",
    "def check_execution_accuracy(schema: str, generated_sql: str, gold_sql: str) -> bool:\n",
    "    try:\n",
    "        conn = setup_database(schema)\n",
    "        result1 = execute_sql_query(conn, generated_sql)\n",
    "        result2 = execute_sql_query(conn, gold_sql)\n",
    "        conn.close()\n",
    "        return result1 == result2\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def evaluate_model(model, tokenizer, samples: List[Dict]) -> Dict:\n",
    "    exact_matches = 0\n",
    "    execution_correct = 0\n",
    "    results = []\n",
    "\n",
    "    for ex in samples:\n",
    "        prompt = f\"### Instruction:\\nWrite only the SQL query that answers the question below, using the given database schema. Do not add explanations, examples, or comments.\\n\\n### Schema:\\n{ex['context']}\\n\\n### Question:\\n{ex['question']}\\n\\n### SQL:\\n\"\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=64,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_p=0.9,\n",
    "            )\n",
    "\n",
    "        decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        raw_generation = decoded[len(prompt):].strip()\n",
    "        print(f\"\\n[RAW MODEL OUTPUT]:\\n{raw_generation}\\n\")\n",
    "        generated_sql = extract_sql(raw_generation)\n",
    "        gold_sql = ex['answer'].strip()\n",
    "\n",
    "        is_exact = generated_sql.lower() == gold_sql.lower()\n",
    "        is_exec_correct = check_execution_accuracy(ex['context'], generated_sql, gold_sql)\n",
    "\n",
    "        exact_matches += is_exact\n",
    "        execution_correct += is_exec_correct\n",
    "\n",
    "        results.append({\n",
    "            'question': ex['question'],\n",
    "            'schema': ex['context'],\n",
    "            'generated_sql': generated_sql,\n",
    "            'gold_sql': gold_sql,\n",
    "            'exact_match': is_exact,\n",
    "            'execution_correct': is_exec_correct\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        'exact_match_count': exact_matches,\n",
    "        'execution_correct_count': execution_correct,\n",
    "        'total_samples': len(samples),\n",
    "        'exact_match_rate': exact_matches / len(samples),\n",
    "        'execution_accuracy': execution_correct / len(samples),\n",
    "        'results': results\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    dataset = load_dataset(\"b-mc2/sql-create-context\", split=\"train\")\n",
    "    split = dataset.train_test_split(test_size=100, seed=1399, shuffle=True)\n",
    "    val_data = split[\"test\"].shuffle(seed=1399)\n",
    "\n",
    "    samples = val_data.select(range(1))\n",
    "    print(f\"Validation size: {len(samples)}\")\n",
    "\n",
    "    finetuned_model_path = \"./llama3-sql-lora/final-merged\"\n",
    "    base_model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "    print(\"\\n=== Loading Fine-Tuned LLaMA 3 Model ===\")\n",
    "    ft_tokenizer = AutoTokenizer.from_pretrained(finetuned_model_path, trust_remote_code=True)\n",
    "    ft_tokenizer.pad_token = ft_tokenizer.eos_token\n",
    "    ft_model = AutoModelForCausalLM.from_pretrained(\n",
    "        finetuned_model_path,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16\n",
    "    ).eval()\n",
    "\n",
    "    print(\"\\n=== Loading Base LLaMA 3 Model ===\")\n",
    "    base_tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
    "    base_tokenizer.pad_token = base_tokenizer.eos_token\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_id,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16\n",
    "    ).eval()\n",
    "\n",
    "    print(\"\\n=== Evaluating Fine-Tuned Model ===\")\n",
    "    ft_results = evaluate_model(ft_model, ft_tokenizer, samples)\n",
    "    print(f\"Exact Matches: {ft_results['exact_match_count']}/{ft_results['total_samples']} \"\n",
    "          f\"({ft_results['exact_match_rate']:.2%})\")\n",
    "    print(f\"Execution Accuracy: {ft_results['execution_correct_count']}/{ft_results['total_samples']} \"\n",
    "          f\"({ft_results['execution_accuracy']:.2%})\")\n",
    "    for i, res in enumerate(ft_results['results'], 1):\n",
    "        print(f\"\\nSample {i}:\")\n",
    "        print(f\"Question: {res['question']}\")\n",
    "        print(f\"Schema: {res['schema']}\")\n",
    "        print(f\"Generated SQL: {res['generated_sql']}\")\n",
    "        print(f\"Gold SQL: {res['gold_sql']}\")\n",
    "        print(f\"Exact Match: {res['exact_match']}\")\n",
    "        print(f\"Execution Correct: {res['execution_correct']}\")\n",
    "\n",
    "    print(\"\\n=== Evaluating Base Model ===\")\n",
    "    base_results = evaluate_model(base_model, base_tokenizer, samples)\n",
    "    print(f\"Exact Matches: {base_results['exact_match_count']}/{base_results['total_samples']} \"\n",
    "          f\"({base_results['exact_match_rate']:.2%})\")\n",
    "    print(f\"Execution Accuracy: {base_results['execution_correct_count']}/{base_results['total_samples']} \"\n",
    "          f\"({base_results['execution_accuracy']:.2%})\")\n",
    "    for i, res in enumerate(base_results['results'], 1):\n",
    "        print(f\"\\nSample {i}:\")\n",
    "        print(f\"Question: {res['question']}\")\n",
    "        print(f\"Schema: {res['schema']}\")\n",
    "        print(f\"Generated SQL: {res['generated_sql']}\")\n",
    "        print(f\"Gold SQL: {res['gold_sql']}\")\n",
    "        print(f\"Exact Match: {res['exact_match']}\")\n",
    "        print(f\"Execution Correct: {res['execution_correct']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0bd0ce-2c9b-4064-aab3-de64d4cc932e",
   "metadata": {
    "id": "ab0bd0ce-2c9b-4064-aab3-de64d4cc932e",
    "outputId": "27dc62d3-2822-406b-b2cf-e1ac70f07f47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation size: 50\n",
      "\n",
      "=== Loading Fine-Tuned LLaMA 3 Model ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 43.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading Base LLaMA 3 Model ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 143.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating Fine-Tuned Model ===\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT distance_duration FROM table_name_3 WHERE date = \"sept 5\" AND race_title = \"le grand prix de trois-rivières\" VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT overall_nt_points FROM table_14407512_24 WHERE points = 248.9 OFFSET 0 LIMIT 1 OFFSET 1 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0\n",
      "\n",
      "Query execution error:\n",
      "SELECT overall_nt_points FROM table_14407512_24 WHERE points = 248.9 OFFSET 0 LIMIT 1 OFFSET 1 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0\n",
      "Error: near \"OFFSET\": syntax error\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT 2007 AS tournament FROM table_name_16 WHERE us_open = \"open\" AND tournament = \"2007\" LIMIT 1 OFFSET 1; SHOW 2007 AS tournament FROM table_name_16 WHERE us_open = \"open\" AND tournament = \"2007\" LIMIT 1 OFFSET 1;\n",
      "\n",
      "Query execution error:\n",
      "SELECT 2007 AS tournament FROM table_name_16 WHERE us_open = \"open\" AND tournament = \"2007\" LIMIT 1 OFFSET 1; SHOW 2007 AS tournament FROM table_name_16 WHERE us_open = \"open\" AND tournament = \"2007\" LIMIT 1 OFFSET 1\n",
      "Error: no such column: us_open\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT MAX(against) FROM table_name_40 WHERE byes > 0 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0\n",
      "\n",
      "Query execution error:\n",
      "SELECT MAX(against) FROM table_name_40 WHERE byes > 0 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0\n",
      "Error: near \"OFFSET\": syntax error\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT MAX(seats) FROM table_name_83 WHERE votes = 244,867 VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR\n",
      "\n",
      "Query execution error:\n",
      "SELECT MAX(seats) FROM table_name_83 WHERE votes = 244,867\n",
      "Error: near \",\": syntax error\n",
      "Query execution error:\n",
      "SELECT MAX(seats) FROM table_name_83 WHERE votes = 244 OFFSET 867\n",
      "Error: near \"OFFSET\": syntax error\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT venue FROM table_name_83 WHERE notes = \"2:28:31\" VARCHAR\n",
      "### Answer:\n",
      "SELECT venue FROM table_name_83 WHERE notes = \"2:28:31\" VARCHAR\n",
      "### SQL:\n",
      "SELECT venue FROM table_name_83 WHERE notes = \"2:28:31\" VARCHAR\n",
      "###\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT country FROM table_name_27 WHERE time = \"7:28.66\" AND rank < 3 OFFSET 1 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0\n",
      "\n",
      "Query execution error:\n",
      "SELECT country FROM table_name_27 WHERE time = \"7:28.66\" AND rank < 3 OFFSET 1 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0 OFFSET 0\n",
      "Error: near \"OFFSET\": syntax error\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT main_use FROM table_name_77 WHERE year < 2004 AND town = \"redfield, arkansas\" VARCHAR\n",
      "```sql\n",
      "SELECT main_use FROM table_name_77 WHERE year < 2004 AND town = \"redfield, arkansas\"\n",
      "``` \n",
      "### Answer:\n",
      "The SQL query for the question\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT construction FROM table_22180353_1 WHERE registration = \"HB-HOS\" SHOW SQL: SELECT construction FROM table_22180353_1 WHERE registration = \"HB-HOS\" END SHOW SQL: SELECT construction FROM table_22180353_1 WHERE registration = \"HB-HOS\" SHOW SQL:\n",
      "\n",
      "Query execution error:\n",
      "SELECT construction FROM table_22180353_1 WHERE registration = \"HB-HOS\" SHOW SQL: SELECT construction FROM table_22180353_1 WHERE registration = \"HB-HOS\" END SHOW SQL: SELECT construction FROM table_22180353_1 WHERE registration = \"HB-HOS\" SHOW SQL:\n",
      "Error: near \"SHOW\": syntax error\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT SUM(reb_) FROM table_name_64 WHERE a_ < 57 AND ast_ < 57 AND no_ = \"7\" GROUP BY b_ HAVING COUNT(b_) = 8 OFFSET 1 LIMIT 1 OFFSET 1 LIMIT 1 OFFSET 1 LIMIT 1 OFFSET 1 LIMIT\n",
      "\n",
      "Query execution error:\n",
      "SELECT SUM(reb_) FROM table_name_64 WHERE a_ < 57 AND ast_ < 57 AND no_ = \"7\" GROUP BY b_ HAVING COUNT(b_) = 8 OFFSET 1 LIMIT 1 OFFSET 1 LIMIT 1 OFFSET 1 LIMIT 1 OFFSET 1 LIMIT\n",
      "Error: near \"OFFSET\": syntax error\n",
      "Query execution error:\n",
      "SELECT AVG(reb_)[b_] FROM table_name_64 WHERE no_[a_] = \"8\" AND ast_[b_] < 57\n",
      "Error: near \"[a_]\": syntax error\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT COUNT(team) FROM table_27721131_8 WHERE game = 45 VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT game FROM table_name_39 WHERE platform_s_ = \"playstation 3\" AND year < 2009 ORDER BY game DESC LIMIT 1 OFFSET 0 VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT builder FROM table_name_49 WHERE ship = \"zeehond\" VARCHAR\n",
      "```sql\n",
      "SELECT builder FROM table_name_49 WHERE ship = \"zeehond\" VARCHAR\n",
      "```  ### Question:\n",
      "The Zeehond was built by whom?\n",
      "\n",
      "### SQL:\n",
      "SELECT builder FROM table_name_49 WHERE ship\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT time FROM table_26842217_18 WHERE result = \"MSST 29–24\" OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET\n",
      "\n",
      "Query execution error:\n",
      "SELECT time FROM table_26842217_18 WHERE result = \"MSST 29–24\" OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET\n",
      "Error: near \"OFFSET\": syntax error\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT opponent FROM table_name_64 WHERE result = \"w 24-14\" LIMIT 1 OFFSET 0 OFFSET 1 OFFSET 2 OFFSET 3 OFFSET 4 OFFSET 5 OFFSET 6 OFFSET 7 OFFSET 8 OFFSET 9 OFFSET 10 OFFSET 11 OFFSET 12 OFFSET 13 OFFSET\n",
      "\n",
      "Query execution error:\n",
      "SELECT opponent FROM table_name_64 WHERE result = \"w 24-14\" LIMIT 1 OFFSET 0 OFFSET 1 OFFSET 2 OFFSET 3 OFFSET 4 OFFSET 5 OFFSET 6 OFFSET 7 OFFSET 8 OFFSET 9 OFFSET 10 OFFSET 11 OFFSET 12 OFFSET 13 OFFSET\n",
      "Error: near \"OFFSET\": syntax error\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT COUNT(total_viewers) FROM table_name_82 WHERE share = \"16.2%\" AND episode_no < 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0\n",
      "\n",
      "Query execution error:\n",
      "SELECT COUNT(total_viewers) FROM table_name_82 WHERE share = \"16.2%\" AND episode_no < 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0\n",
      "Error: near \"OFFSET\": syntax error\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT high_assists FROM table_name_44 WHERE date = \"november 25\" VARCHAR\n",
      "SELECT high_assists FROM table_name_44 WHERE date = \"november 25\" VARCHAR\n",
      "SELECT high_assists FROM table_name_44 WHERE date = \"november 25\" VARCHAR\n",
      "SELECT high_assists\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT administration FROM table_name_21 WHERE division = \"ykkönen (first division)\" AND position = 1 AND season = 1996\n",
      "### Answer:\n",
      "1996_1997_1998_1999_2000_2001_2002_2003_2004_2005_\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT kickoff_ FROM table_name_9 WHERE attendance = \"58,120\" AND a_ = \"0\" OFFSET 1 LIMIT 1 OFFSET 1 LIMIT 1 OFFSET 1 LIMIT 1 OFFSET 1 LIMIT 1 OFFSET 1 LIMIT 1 OFFSET 1 LIMIT 1 OFFSET 1 LIMIT\n",
      "\n",
      "Query execution error:\n",
      "SELECT kickoff_ FROM table_name_9 WHERE attendance = \"58,120\" AND a_ = \"0\" OFFSET 1 LIMIT 1 OFFSET 1 LIMIT 1 OFFSET 1 LIMIT 1 OFFSET 1 LIMIT 1 OFFSET 1 LIMIT 1 OFFSET 1 LIMIT 1 OFFSET 1 LIMIT\n",
      "Error: near \"OFFSET\": syntax error\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT rider FROM table_name_88 WHERE constructor = \"honda\" AND team = \"scot racing\" AND rounds = \"6-17\" VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT AVG(silver) FROM table_name_44 WHERE nation = \"ger\" AND bronze > 3; View Answer\n",
      "### Explanation:\n",
      "The average number of silver medals for Germany (GER) having more than 3 bronze medals is the average number of silver medals for the nations that are Germany and have more than\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT score FROM table_name_59 WHERE runners_up = \"tsv siegen\" VARCHAR\n",
      "```sql\n",
      "SELECT score FROM table_name_59 WHERE runners_up = \"tsv siegen\" VARCHAR\n",
      "```  ### Question:\n",
      "What is the score when TSV Siegen was the runner-up?\n",
      "\n",
      "### SQL:\n",
      "SELECT\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT laps FROM table_name_77 WHERE manufacturer = \"yamaha\" AND rider = \"valentino rossi\" VARCHAR; VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT COUNT(played) FROM table_2208838_4 WHERE points = \"927\" OFFSET 0 ROWS LIMIT 1 OFFSET 0 ROWS LIMIT 1 OFFSET 0 ROWS LIMIT 1 OFFSET 0 ROWS LIMIT 1 OFFSET 0 ROWS LIMIT 1 OFFSET 0 ROWS\n",
      "\n",
      "Query execution error:\n",
      "SELECT COUNT(played) FROM table_2208838_4 WHERE points = \"927\" OFFSET 0 ROWS LIMIT 1 OFFSET 0 ROWS LIMIT 1 OFFSET 0 ROWS LIMIT 1 OFFSET 0 ROWS LIMIT 1 OFFSET 0 ROWS LIMIT 1 OFFSET 0 ROWS\n",
      "Error: near \"OFFSET\": syntax error\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT pop_density__per_km²_ FROM table_1686313_1 WHERE barangay = \"Tiptip\" VARCHAR\n",
      "SELECT COUNT(pop_density__per_km²_) FROM table_1686313_1 WHERE barangay = \"Tiptip\" VARCHAR\n",
      "SELECT pop_density__per_km²_ FROM\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT sanskrit_संस्कृतम् FROM table_name_23 WHERE tamil_தமிழ் = \"rōkiṇi ரோகிணி\" VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT 2 AS leg FROM table_name_44 WHERE team__number1 = \"rubin kazan\" OFFSET 1 LIMIT 1\n",
      "### SQL: \n",
      "SELECT 2 AS leg FROM table_name_44 WHERE team__number1 = \"rubin kazan\" OFFSET 1 LIMIT 1\n",
      "### SQL:\n",
      "\n",
      "Query execution error:\n",
      "SELECT 2 AS leg FROM table_name_44 WHERE team__number1 = \"rubin kazan\" OFFSET 1 LIMIT 1\n",
      "Error: near \"OFFSET\": syntax error\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT attendance FROM table_name_77 WHERE date = \"august 23\" VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT COUNT(base_pairs) FROM table_name_90 WHERE strain = \"tohamai\" VARCHAR\n",
      "SELECT COUNT(base_pairs) FROM table_name_90 WHERE strain = \"tohamai\" VARCHAR\n",
      "SELECT COUNT(base_pairs) FROM table_name_90 WHERE strain = \"tohamai\" VARCHAR\n",
      "SELECT COUNT(base_pairs\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT MIN(against) FROM table_name_84 WHERE wins < 9 AND draws < 0\n",
      "```\n",
      "SELECT MIN(against) FROM table_name_84 WHERE wins < 9 AND draws < 0\n",
      "``` SQL\n",
      "``` SQL:\n",
      "SELECT MIN(against) FROM table_name_84 WHERE wins <\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT total FROM table_26375386_22 WHERE public = 3 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET\n",
      "\n",
      "Query execution error:\n",
      "SELECT total FROM table_26375386_22 WHERE public = 3 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET\n",
      "Error: near \"OFFSET\": syntax error\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT safe FROM table_12305325_4 WHERE eliminated = \"John and Nicole\" OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT\n",
      "\n",
      "Query execution error:\n",
      "SELECT safe FROM table_12305325_4 WHERE eliminated = \"John and Nicole\" OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT\n",
      "Error: near \"OFFSET\": syntax error\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT current_venue FROM table_14903081_1 WHERE tournament = \"Miami Masters\" VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT dots FROM table_name_29 WHERE ellipsis = \"0.012345679…\" VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT MIN(year_s_) FROM table_name_81 WHERE season = 4 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET\n",
      "\n",
      "Query execution error:\n",
      "SELECT MIN(year_s_) FROM table_name_81 WHERE season = 4 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET\n",
      "Error: near \"OFFSET\": syntax error\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT centerfold_model FROM table_name_56 WHERE cover_model = \"julie lynn cialini\" VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT SUM(losses) FROM table_name_52 WHERE year > 2001\n",
      "```\n",
      "SELECT SUM(losses) FROM table_name_52 WHERE year > 2001\n",
      "```\n",
      "### Explanation:\n",
      "The SQL query sums up the losses for the years later than 2001. The question asks for the total losses\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT max_power_at_rpm FROM table_name_90 WHERE engine_name = \"2.0 tdi\" AND displacement = \"1968cc\" OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT\n",
      "\n",
      "Query execution error:\n",
      "SELECT max_power_at_rpm FROM table_name_90 WHERE engine_name = \"2.0 tdi\" AND displacement = \"1968cc\" OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT\n",
      "Error: near \"OFFSET\": syntax error\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT replaced_by FROM table_name_87 WHERE team = \"bournemouth\" AND outgoing_manager = \"kevin bond\"  SHOW TABLE: CREATE TABLE table_name_87 (replaced_by VARCHAR, team VARCHAR, outgoing_manager VARCHAR) SHOW TABLE: CREATE TABLE table_name_87 (replaced_by VARCHAR, team VARCHAR\n",
      "\n",
      "Query execution error:\n",
      "SELECT replaced_by FROM table_name_87 WHERE team = \"bournemouth\" AND outgoing_manager = \"kevin bond\" SHOW TABLE: CREATE TABLE table_name_87 (replaced_by\n",
      "Error: near \"SHOW\": syntax error\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT AVG(T1.episode) FROM table_name_96 AS T1 WHERE T1.original_airdate = \"march 21, 2010\" AND T1.season < 3 OFFSET 1 LIMIT 1 OFFSET 1 LIMIT 1 OFFSET 1 LIMIT 1 OFFSET 1 LIMIT 1\n",
      "\n",
      "Query execution error:\n",
      "SELECT AVG(T1.episode) FROM table_name_96 AS T1 WHERE T1.original_airdate = \"march 21, 2010\" AND T1.season < 3 OFFSET 1 LIMIT 1 OFFSET 1 LIMIT 1 OFFSET 1 LIMIT 1 OFFSET 1 LIMIT 1\n",
      "Error: near \"OFFSET\": syntax error\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT MIN(gold) FROM table_name_68 WHERE silver = 0 VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT march FROM table_name_3 WHERE november = \"cara wakelin\" VARCHAR SHOW 2 VARCHAR SHOW 2 VARCHAR SHOW 2 VARCHAR SHOW 2 VARCHAR SHOW 2 VARCHAR SHOW 2 VARCHAR SHOW 2 VARCHAR SHOW 2 VARCHAR SHOW 2 VARCHAR SHOW 2 VARCHAR SHOW 2 VARCHAR SHOW\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT away_team AS opponents_score FROM table_name_99 WHERE home_team = \"geelong\" VARCHAR; VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT team_1 FROM table_name_13 WHERE team_2 = \"vfl gummersbach\" VARCHAR\n",
      "```\n",
      "```SQL\n",
      "SELECT team_1 FROM table_name_13 WHERE team_2 = \"vfl gummersbach\" VARCHAR\n",
      "```\n",
      "```\n",
      "\n",
      "### Question:\n",
      "What is the team 2\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT MAX(year) FROM table_name_66 WHERE category = \"best film\" OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1\n",
      "\n",
      "Query execution error:\n",
      "SELECT MAX(year) FROM table_name_66 WHERE category = \"best film\" OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1 OFFSET 0 LIMIT 1\n",
      "Error: near \"OFFSET\": syntax error\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT SUM(year) FROM table_name_7 WHERE expenditure = 55 AND income < 36.2 ORDER BY year DESC LIMIT 1 OFFSET 1 OFFSET 1 OFFSET 1 OFFSET 1 OFFSET 1 OFFSET 1 OFFSET 1 OFFSET 1 OFFSET 1 OFFSET 1 OFFSET 1 OFFSET 1\n",
      "\n",
      "Query execution error:\n",
      "SELECT SUM(year) FROM table_name_7 WHERE expenditure = 55 AND income < 36.2 ORDER BY year DESC LIMIT 1 OFFSET 1 OFFSET 1 OFFSET 1 OFFSET 1 OFFSET 1 OFFSET 1 OFFSET 1 OFFSET 1 OFFSET 1 OFFSET 1 OFFSET 1 OFFSET 1\n",
      "Error: near \"OFFSET\": syntax error\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT tournament FROM table_name_36 WHERE date = \"oct 23\" VARCHAR\n",
      "```\n",
      "SELECT tournament FROM table_name_36 WHERE date = \"oct 23\" VARCHAR\n",
      "``` SQL: CREATE TABLE table_name_36 (tournament VARCHAR, date VARCHAR) Question: What is the name of the Tournament on oct\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT record_set FROM table_name_30 WHERE actor = \"walter brennan\" AND year < 1941 VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT album FROM table_name_93 WHERE year < 2008 AND title = \"we're not made in the usa\" VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR; VARCHAR\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT affiliation FROM table_name_37 WHERE location = \"towson, md\" VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR VARCHAR\n",
      "\n",
      "Exact Matches: 21/50 (42.00%)\n",
      "Execution Accuracy: 40/50 (80.00%)\n",
      "\n",
      "=== Evaluating Base Model ===\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "```sql\n",
      "SELECT distance_duration \n",
      "FROM table_name_3 \n",
      "WHERE date = 'Sept 5' AND race_title = 'Le Grand Prix de Trois-Rivières';\n",
      "```  ```\n",
      "```  ```\n",
      "```\n",
      "```  ```\n",
      "```  ```\n",
      "```  ```\n",
      "```  ```\n",
      "```  ```\n",
      "```  ```\n",
      "```\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT overall_nt_points FROM table_14407512_24 WHERE points = '248.9';  ###### 1.4 seconds to execute\n",
      "```sql\n",
      "```sql\n",
      "SELECT overall_nt_points FROM table_14407512_24 WHERE points = '248.9';\n",
      "````\n",
      "````\n",
      "````\n",
      "```\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT * FROM table_name_16 WHERE tournament = '2007 US Open';  ### Answer:  ### No result (table is empty)  ### Please add the values to the table first.  SELECT '2007 US Open' AS tournament; INSERT INTO table_name_16 (tournament) VALUES ('2007\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "```\n",
      "SELECT MAX(against)\n",
      "FROM table_name_40\n",
      "WHERE byes > 0;\n",
      "```  ### Instruction:\n",
      "Write only the SQL query that answers the question below, using the given database schema. Do not add explanations, examples, or comments.\n",
      "\n",
      "### Schema:\n",
      "CREATE TABLE table_name_40 (against INTEGER\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT seats FROM table_name_83 WHERE votes = '244,867' ORDER BY seats DESC LIMIT 1;  ####### End of Instruction ####### \n",
      "SELECT seats FROM table_name_83 WHERE votes = '244,867' ORDER BY seats DESC LIMIT 1;  ####### End of Instruction #######\n",
      "\n",
      "Query execution error:\n",
      "SELECT MAX(seats) FROM table_name_83 WHERE votes = 244 OFFSET 867\n",
      "Error: near \"OFFSET\": syntax error\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "```sql\n",
      "SELECT venue\n",
      "FROM table_name_83\n",
      "WHERE notes = '2:28:31';\n",
      "```  ### End of SQL\n",
      "```sql\n",
      "```\n",
      "### End of SQL\n",
      "```sql\n",
      "```  ### End of SQL\n",
      "```sql\n",
      "```  ### End of SQL\n",
      "```sql\n",
      "```\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "```\n",
      "SELECT country\n",
      "FROM table_name_27\n",
      "WHERE time = '7:28.66' AND rank < 3;\n",
      "``` \n",
      "### End of Instruction. ###\n",
      "\n",
      "### End of SQL Query. ###\n",
      "\n",
      "### End of File. ###\n",
      "\n",
      "### End of Schema. ###\n",
      "\n",
      "### End of Question. ###\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT main_use \n",
      "FROM table_name_77 \n",
      "WHERE town = 'Redfield' AND year < '2004' \n",
      "LIMIT 1;\n",
      "### End of SQL query. ###\n",
      "\n",
      "### Answer:\n",
      "(Insert your answer here.) ###\n",
      "\n",
      "### Result:\n",
      "The main use of the structure in Redfield, Arkansas before\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT construction \n",
      "FROM table_22180353_1 \n",
      "WHERE registration = 'HB-HOS';  ### Answer: ### SELECT construction FROM table_22180353_1 WHERE registration = 'HB-HOS';  ### End of Answer.  ### End of Instruction.  ### End of File.  ###\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "```sql\n",
      "SELECT * \n",
      "FROM table_name_64 \n",
      "WHERE reb_ = 8 AND ast_ < 57\n",
      "```  ### Answer:\n",
      "```sql\n",
      "SELECT * \n",
      "FROM table_name_64 \n",
      "WHERE reb_ = 8 AND ast_ < 57\n",
      "```  ### Instruction:\n",
      "Write only the SQL\n",
      "\n",
      "Query execution error:\n",
      "SELECT AVG(reb_)[b_] FROM table_name_64 WHERE no_[a_] = \"8\" AND ast_[b_] < 57\n",
      "Error: near \"[a_]\": syntax error\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT COUNT(DISTINCT team) FROM table_27721131_8 WHERE game = '45';  ### Answer:  ### 0  ### 1  ### 2  ### 3  ### 4  ### 5  ### 6  ### 7  ### 8  ###\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "```sql\n",
      "SELECT game \n",
      "FROM table_name_39 \n",
      "WHERE platform_s_ = 'Playstation 3' AND year < '2009';\n",
      "```  ### End of SQL query.  ### Instruction:  Write only the SQL query that answers the question below, using the given database schema. Do not add explanations\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT builder\n",
      "FROM table_name_49\n",
      "WHERE ship = 'Zeehond';  ### SQL query that answers the question. ######  END SQL query that answers the question.  END  END  END  END  END  END  END  END  END  END  END  END  END\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT time\n",
      "FROM table_26842217_18\n",
      "WHERE result ='msst' AND time BETWEEN '29-24' AND '29-24';  // This query should be adjusted.  // Here's the adjusted query:\n",
      "SELECT time\n",
      "FROM table_26842217_18\n",
      "WHERE result =\n",
      "\n",
      "Query execution error:\n",
      "SELECT time FROM table_26842217_18 WHERE result ='msst' AND time BETWEEN '29-24' AND '29-24'; // This query should be adjusted. // Here's the adjusted query: SELECT time FROM table_26842217_18 WHERE result =\n",
      "Error: You can only execute one statement at a time.\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT opponent\n",
      "FROM table_name_64\n",
      "WHERE result = 'W 24-14';  ### Answer:  SELECT opponent FROM table_name_64 WHERE result = 'W 24-14';  #### End of Instruction.  ####  ####  ####  ####  ####  ####  ####  ####\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "```sql\n",
      "SELECT COUNT(*) \n",
      "FROM table_name_82 \n",
      "WHERE share = '16.2%' AND episode_no < '1';\n",
      "```  ### End of Instruction.  ###  If you need help, you can ask.  ###  Please do not change the schema or the question.  ###  Good\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "```sql\n",
      "SELECT high_assists \n",
      "FROM table_name_44 \n",
      "WHERE date = 'november 25'\n",
      "``` \n",
      "### Output:\n",
      "High assists\n",
      "------------ \n",
      " Value of high assists for November 25\n",
      "```sql\n",
      "```sql\n",
      "```\n",
      "### Note:\n",
      "Please replace the table_name_44 with your actual table\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "```sql\n",
      "SELECT administration\n",
      "FROM table_name_21\n",
      "WHERE season = '1996' AND division = 'Ykkönen' AND position = '1st';\n",
      "```  #sql #query #database #schema #question #answer #sqlquery #table_name_21 #administration #division #position #\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT kickoff_ FROM table_name_9 WHERE attendance = '58120'; \n",
      "```sql\n",
      "```sql\n",
      "SELECT kickoff_ FROM table_name_9 WHERE attendance = '58120'; \n",
      "``` ```\n",
      "```\n",
      "```\n",
      "```\n",
      "``` ```\n",
      "```\n",
      "```\n",
      "```\n",
      "``` ```\n",
      "```\n",
      "```\n",
      "```\n",
      "```\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "```\n",
      "SELECT rider\n",
      "FROM table_name_88\n",
      "WHERE team = 'Scot Racing' AND constructor = 'Honda' AND rounds BETWEEN '6' AND '17';\n",
      "```  #### 2022-04-21 23:47:22 #### 1 #### 0.0009s #### 0\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "```sql\n",
      "SELECT AVG(silver) \n",
      "FROM table_name_44 \n",
      "WHERE nation = 'GER' AND bronze > 3\n",
      "```  ### End of SQL query.  ###  Please do not modify anything above this line.  ###  You can modify the SQL query below.  ###  Please answer the\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT score FROM table_name_59 WHERE runners_up = 'TSV Siegen';  ### END OF SQL ### END OF INSTRUCTION ### END OF QUESTION ### END OF SCHEMA ### END OF SQL ### END OF INSTRUCTION ### END OF QUESTION ### END OF SCHEMA ### END OF SQL ### END OF INSTRUCTION ###\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "```sql\n",
      "SELECT laps \n",
      "FROM table_name_77 \n",
      "WHERE manufacturer = 'Yamaha' AND rider = 'Valentino Rossi';\n",
      "```\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT COUNT(*) FROM table_2208838_4 WHERE played =? AND points = '927';  // replace? with the actual value of the played column for the player with 927 points.  // If you don't know the value, you can't answer this question.  // You should return the\n",
      "\n",
      "Query execution error:\n",
      "SELECT COUNT(*) FROM table_2208838_4 WHERE played =? AND points = '927'; // replace? with the actual value of the played column for the player with 927 points. // If you don't know the value, you can't answer this question. // You should return the\n",
      "Error: You can only execute one statement at a time.\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT * FROM table_1686313_1 WHERE barangay = 'tiptip';  ### Note: This SQL query assumes that the column names are case-sensitive. If the column names are case-insensitive, the query should be modified accordingly.  ### Also, this query will return all columns (pop_density\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "```sql\n",
      "SELECT sanskrit_संस्कृतम्\n",
      "FROM table_name_23\n",
      "WHERE tamil_தமிழ் = 'रோகிணி';\n",
      "```  ### Output:\n",
      "```sql\n",
      "```\n",
      "### Explanation:\n",
      "```sql\n",
      "```  ### Example:\n",
      "```sql\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT leg FROM table_name_44 WHERE team__number1 = 'Rubin Kazan' LIMIT 1 OFFSET 1;  ### Answer:  SELECT leg FROM table_name_44 WHERE team__number1 = 'Rubin Kazan' LIMIT 1 OFFSET 1;  ### Instruction: Write only the\n",
      "\n",
      "Query execution error:\n",
      "SELECT leg FROM table_name_44 WHERE team__number1 = 'Rubin Kazan' LIMIT 1 OFFSET 1\n",
      "Error: no such column: leg\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT attendance FROM table_name_77 WHERE date = 'August 23';  ### End of SQL query.  ###  ###  ###  ###  ###  ###  ###  ###  ###  ###  ###  ###  ###  ###  ###  ###  ###  ###  ###  ###  ###\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT COUNT(base_pairs) FROM table_name_90 WHERE strain = 'tohamai';  ### End of SQL query. ###\n",
      "\n",
      "### Output:\n",
      "The output will be the number of base pairs in the tohamai strain.  ### End of Output. ###\n",
      "\n",
      "### Instruction:\n",
      "Write only the SQL query that answers\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "```\n",
      "SELECT MIN(against) \n",
      "FROM table_name_84 \n",
      "WHERE wins < 9 AND draws < 0;\n",
      "``` \n",
      "\n",
      "### Output:\n",
      "```\n",
      "```\n",
      "### Explanation:\n",
      "This SQL query uses the MIN function to find the lowest against value in the table_name_84 table, but only for the rows where\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT total FROM table_26375386_22 WHERE public = '3';  ###### This query will give us the total for 3 public. \n",
      "###### The result is in the 'total' column.  ######  ###### \n",
      "######  ###### \n",
      "######  ###### \n",
      "####\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT * FROM table_12305325_4 WHERE safe ='safe' AND (eliminated = 'John' OR eliminated = 'Nicole') NOT;  // Not sure how to proceed with the query\n",
      "```\n",
      "SELECT * FROM table_12305325_4 WHERE safe ='safe' AND eliminated\n",
      "\n",
      "Query execution error:\n",
      "SELECT * FROM table_12305325_4 WHERE safe ='safe' AND (eliminated = 'John' OR eliminated = 'Nicole') NOT; // Not sure how to proceed with the query ``` SELECT * FROM table_12305325_4 WHERE safe ='safe' AND eliminated\n",
      "Error: near \";\": syntax error\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT current_venue\n",
      "FROM table_14903081_1\n",
      "WHERE tournament = 'Miami Masters';  ###### 1\n",
      "```\n",
      "SELECT current_venue\n",
      "FROM table_14903081_1\n",
      "WHERE tournament = 'Miami Masters';\n",
      "```  ###### 1\n",
      "```\n",
      "SELECT current_venue\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT dots FROM table_name_29 WHERE ellipsis = '0.012345679...';  ### Answer:\n",
      "```\n",
      "SELECT dots FROM table_name_29 WHERE ellipsis = '0.012345679...';\n",
      "```  ### Explanation:  This SQL query selects the value in the \"dots\" column of the\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT MIN(year_s_) FROM table_name_81 WHERE season IN ('S1', 'S2', 'S3', 'S4');  ####\n",
      "####  End of the SQL query  ####\n",
      "####  Do not modify this line  ####\n",
      "####  End of the SQL query  ####\n",
      "####\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT centerfold_model\n",
      "FROM table_name_56\n",
      "WHERE cover_model = 'Julie Lynn Cialini';  ### Answer. ### \n",
      "```\n",
      "SELECT centerfold_model\n",
      "FROM table_name_56\n",
      "WHERE cover_model = 'Julie Lynn Cialini';\n",
      "```  ### Answer. ### \n",
      "```  SELECT\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT * \n",
      "FROM table_name_52 \n",
      "WHERE year > 2001;  ### SQL query to answer the question.  ### Instruction:  Write only the SQL query that answers the question below, using the given database schema. Do not add explanations, examples, or comments.  ### Schema:  CREATE TABLE\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT max_power_at_rpm \n",
      "FROM table_name_90 \n",
      "WHERE engine_name = '2.0 TDI' AND displacement = '1968cc';  ###\n",
      "\n",
      "### Output:\n",
      "The output will be the maximum power at rpm for the engine named 2.0 TDI that has a 1968cc\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT replaced_by\n",
      "FROM table_name_87\n",
      "WHERE team = 'bournemouth' AND outgoing_manager = 'kevin bond';  ###### 1 ######  ###### 1 ######  ###### 1 ######  ###### 1 ######  ###### 1 ######  ######\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT AVG(episode) \n",
      "FROM table_name_96 \n",
      "WHERE original_airdate = 'March 21, 2010' AND season < 3;  ### Answer:  ### End of SQL query.  ### End of file.  ###  ###  ###  ###  ###  ###  ###\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "```\n",
      "SELECT *\n",
      "FROM table_name_68\n",
      "WHERE gold = (SELECT MIN(gold) FROM table_name_68) AND silver = 0;\n",
      "```  ####\n",
      "####\n",
      "\n",
      "######\n",
      "\n",
      "\n",
      "\n",
      "######\n",
      "\n",
      "\n",
      "######\n",
      "\n",
      "\n",
      "######\n",
      "\n",
      "\n",
      "\n",
      "######\n",
      "\n",
      "\n",
      "######\n",
      "\n",
      "\n",
      "######\n",
      "\n",
      "\n",
      "######\n",
      "\n",
      "\n",
      "######\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT march \n",
      "FROM table_name_3 \n",
      "WHERE march IN (SELECT march \n",
      "                FROM table_name_3 \n",
      "                WHERE november = 'Cara Wakelin');  ####### 1\n",
      "```\n",
      "SELECT march \n",
      "FROM table_name_3 \n",
      "WHERE march IN (SELECT march \n",
      "                FROM table_name_3\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT home_team, away_team FROM table_name_99 WHERE home_team = 'Geelong'; \n",
      "```sql\n",
      "```sql\n",
      "SELECT home_team, away_team FROM table_name_99 WHERE home_team = 'Geelong'; \n",
      "```\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "### Instruction:\n",
      "Write only the SQL query that answers the question below,\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT team_1 FROM table_name_13 WHERE team_2 = 'vfl gummersbach';  ####### 1 #######  SELECT team_1 FROM table_name_13 WHERE team_2 = 'vfl gummersbach'; \n",
      "####### 2 #######  SELECT team_1 FROM table\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT year FROM table_name_66 WHERE category = 'best film';  ### End of SQL Query. ###  ####  ####  ####  ####  ####  ####  ####  ####  ####  ####  ####  ####  ####  ####  ####  ####  ####  ####  ####  ####  ####\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT year\n",
      "FROM table_name_7\n",
      "WHERE expenditure = '55' AND income < '36.2';  ######  No need to write the table name in the SQL query. The SQL query is already written.  ######  The table name is 'table_name_7'.   ######\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT tournament FROM table_name_36 WHERE date = 'oct 23';  ###### 1.7 seconds to answer.  ###### 1.7 seconds to answer.  ###### 1.7 seconds to answer.  ###### 1.7 seconds to answer.  ###### 1\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT * FROM table_name_30 WHERE actor = 'Walter Brennan' AND year < '1941';  ######  This SQL query will answer the question above. It will select all records from the table where the actor is 'Walter Brennan' and the year is less than 1941.  ####\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT album \n",
      "FROM table_name_93 \n",
      "WHERE year < '2008' AND title = 'We''re not Made in the USA';  ### Answer:  This SQL query selects the album name from the table_name_93 where the year is less than 2008 and the title is 'We're not\n",
      "\n",
      "\n",
      "[RAW MODEL OUTPUT]:\n",
      "SELECT affiliation FROM table_name_37 WHERE location = 'towson, md';  ####### 1 #######  ####### 1 #######  ####### 1 #######  ####### 1 #######  ####### 1 #######  ####### 1 #######  ####### 1\n",
      "\n",
      "Exact Matches: 2/50 (4.00%)\n",
      "Execution Accuracy: 42/50 (84.00%)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import re\n",
    "import sqlite3\n",
    "from datasets import load_dataset\n",
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "def extract_sql(text: str) -> str:\n",
    "    stop_tokens = [\"###\", \"Explanation\", \"View\", \"VARCHAR\", \"SHOW SQL\", \"OFFSET\", \"LIMIT\"]\n",
    "\n",
    "    for token in stop_tokens:\n",
    "        if token in text:\n",
    "            text = text.split(token)[0]\n",
    "\n",
    "    code_block = re.search(r\"```(?:sql)?\\s*(SELECT .*?)```\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if code_block:\n",
    "        sql = code_block.group(1)\n",
    "    else:\n",
    "        example_block = re.search(r\"###\\s*Example:\\s*(SELECT .*?)(\\n|$)\", text, re.DOTALL | re.IGNORECASE)\n",
    "        if example_block:\n",
    "            sql = example_block.group(1)\n",
    "        else:\n",
    "            fallback = re.search(r\"(SELECT|INSERT|UPDATE|DELETE|CREATE|ALTER|DROP)\\b.*\", text, re.IGNORECASE | re.DOTALL)\n",
    "            sql = fallback.group(0) if fallback else text\n",
    "\n",
    "    sql = ' '.join(sql.strip().split())\n",
    "    return sql.rstrip(';') + ';'\n",
    "\n",
    "def setup_database(schema: str) -> sqlite3.Connection:\n",
    "    conn = sqlite3.connect(\":memory:\")\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.executescript(schema)\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        print(f\"DB setup error:\\n{schema}\\nError: {e}\")\n",
    "    return conn\n",
    "\n",
    "def execute_sql_query(conn: sqlite3.Connection, sql_query: str) -> List[Dict]:\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(sql_query)\n",
    "        return cursor.fetchall()\n",
    "    except Exception as e:\n",
    "        print(f\"Query execution error:\\n{sql_query}\\nError: {e}\")\n",
    "        return []\n",
    "\n",
    "def check_execution_accuracy(schema: str, generated_sql: str, gold_sql: str) -> bool:\n",
    "    try:\n",
    "        conn = setup_database(schema)\n",
    "        result1 = execute_sql_query(conn, generated_sql)\n",
    "        result2 = execute_sql_query(conn, gold_sql)\n",
    "        conn.close()\n",
    "        return result1 == result2\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def evaluate_model(model, tokenizer, samples: List[Dict]) -> Dict:\n",
    "    exact_matches = 0\n",
    "    execution_correct = 0\n",
    "    results = []\n",
    "\n",
    "    for ex in samples:\n",
    "        prompt = f\"### Instruction:\\nWrite only the SQL query that answers the question below, using the given database schema. Do not add explanations, examples, or comments.\\n\\n### Schema:\\n{ex['context']}\\n\\n### Question:\\n{ex['question']}\\n\\n### SQL:\\n\"\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=64,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_p=0.9,\n",
    "            )\n",
    "\n",
    "        decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        raw_generation = decoded[len(prompt):].strip()\n",
    "        print(f\"\\n[RAW MODEL OUTPUT]:\\n{raw_generation}\\n\")\n",
    "        generated_sql = extract_sql(raw_generation)\n",
    "        gold_sql = ex['answer'].strip()\n",
    "\n",
    "        is_exact = generated_sql.lower() == gold_sql.lower()\n",
    "        is_exec_correct = check_execution_accuracy(ex['context'], generated_sql, gold_sql)\n",
    "\n",
    "        exact_matches += is_exact\n",
    "        execution_correct += is_exec_correct\n",
    "\n",
    "        results.append({\n",
    "            'question': ex['question'],\n",
    "            'schema': ex['context'],\n",
    "            'generated_sql': generated_sql,\n",
    "            'gold_sql': gold_sql,\n",
    "            'exact_match': is_exact,\n",
    "            'execution_correct': is_exec_correct\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        'exact_match_count': exact_matches,\n",
    "        'execution_correct_count': execution_correct,\n",
    "        'total_samples': len(samples),\n",
    "        'exact_match_rate': exact_matches / len(samples),\n",
    "        'execution_accuracy': execution_correct / len(samples),\n",
    "        'results': results\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    dataset = load_dataset(\"b-mc2/sql-create-context\", split=\"train\")\n",
    "    split = dataset.train_test_split(test_size=100, seed=1399, shuffle=True)\n",
    "    val_data = split[\"test\"].shuffle(seed=1399)\n",
    "\n",
    "    samples = val_data.select(range(50))\n",
    "    print(f\"Validation size: {len(samples)}\")\n",
    "\n",
    "    finetuned_model_path = \"./llama3-sql-lora/final-merged\"\n",
    "    base_model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "    print(\"\\n=== Loading Fine-Tuned LLaMA 3 Model ===\")\n",
    "    ft_tokenizer = AutoTokenizer.from_pretrained(finetuned_model_path, trust_remote_code=True)\n",
    "    ft_tokenizer.pad_token = ft_tokenizer.eos_token\n",
    "    ft_model = AutoModelForCausalLM.from_pretrained(\n",
    "        finetuned_model_path,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16\n",
    "    ).eval()\n",
    "\n",
    "    print(\"\\n=== Loading Base LLaMA 3 Model ===\")\n",
    "    base_tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
    "    base_tokenizer.pad_token = base_tokenizer.eos_token\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_id,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16\n",
    "    ).eval()\n",
    "\n",
    "    print(\"\\n=== Evaluating Fine-Tuned Model ===\")\n",
    "    ft_results = evaluate_model(ft_model, ft_tokenizer, samples)\n",
    "    print(f\"Exact Matches: {ft_results['exact_match_count']}/{ft_results['total_samples']} \"\n",
    "          f\"({ft_results['exact_match_rate']:.2%})\")\n",
    "    print(f\"Execution Accuracy: {ft_results['execution_correct_count']}/{ft_results['total_samples']} \"\n",
    "          f\"({ft_results['execution_accuracy']:.2%})\")\n",
    "    # for i, res in enumerate(ft_results['results'], 1):\n",
    "    #     print(f\"\\nSample {i}:\")\n",
    "    #     print(f\"Question: {res['question']}\")\n",
    "    #     print(f\"Schema: {res['schema']}\")\n",
    "    #     print(f\"Generated SQL: {res['generated_sql']}\")\n",
    "    #     print(f\"Gold SQL: {res['gold_sql']}\")\n",
    "    #     print(f\"Exact Match: {res['exact_match']}\")\n",
    "    #     print(f\"Execution Correct: {res['execution_correct']}\")\n",
    "\n",
    "    print(\"\\n=== Evaluating Base Model ===\")\n",
    "    base_results = evaluate_model(base_model, base_tokenizer, samples)\n",
    "    print(f\"Exact Matches: {base_results['exact_match_count']}/{base_results['total_samples']} \"\n",
    "          f\"({base_results['exact_match_rate']:.2%})\")\n",
    "    print(f\"Execution Accuracy: {base_results['execution_correct_count']}/{base_results['total_samples']} \"\n",
    "          f\"({base_results['execution_accuracy']:.2%})\")\n",
    "    # for i, res in enumerate(base_results['results'], 1):\n",
    "    #     print(f\"\\nSample {i}:\")\n",
    "    #     print(f\"Question: {res['question']}\")\n",
    "    #     print(f\"Schema: {res['schema']}\")\n",
    "    #     print(f\"Generated SQL: {res['generated_sql']}\")\n",
    "    #     print(f\"Gold SQL: {res['gold_sql']}\")\n",
    "    #     print(f\"Exact Match: {res['exact_match']}\")\n",
    "    #     print(f\"Execution Correct: {res['execution_correct']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ada79b-50a1-4379-953b-0840a4bc98b3",
   "metadata": {
    "id": "d8ada79b-50a1-4379-953b-0840a4bc98b3",
    "outputId": "1376aa8a-a4cc-4c63-8b7c-ec612688ff75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading Fine-Tuned LLaMA 3 Model ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/utils/modeling.py:1569: UserWarning: Current model requires 128 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 41.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading Base LLaMA 3 Model ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 133.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating Fine-Tuned Model ===\n",
      "Exact Matches: 0/50 (0.00%)\n",
      "Execution Accuracy: 45/50 (90.00%)\n",
      "\n",
      "=== Evaluating Base Model ===\n",
      "Exact Matches: 0/50 (0.00%)\n",
      "Execution Accuracy: 37/50 (74.00%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import re\n",
    "import sqlite3\n",
    "from datasets import load_dataset\n",
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_sql(text: str) -> str:\n",
    "    stop_tokens = [\"###\", \"Explanation\", \"View\", \"VARCHAR\", \"SHOW SQL\", \"OFFSET\", \"LIMIT\"]\n",
    "\n",
    "    for token in stop_tokens:\n",
    "        if token in text:\n",
    "            text = text.split(token)[0]\n",
    "\n",
    "    code_block = re.search(r\"```(?:sql)?\\s*(SELECT .*?)```\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if code_block:\n",
    "        sql = code_block.group(1)\n",
    "    else:\n",
    "        example_block = re.search(r\"###\\s*Example:\\s*(SELECT .*?)(\\n|$)\", text, re.DOTALL | re.IGNORECASE)\n",
    "        if example_block:\n",
    "            sql = example_block.group(1)\n",
    "        else:\n",
    "            fallback = re.search(r\"(SELECT|INSERT|UPDATE|DELETE|CREATE|ALTER|DROP)\\b.*\", text, re.IGNORECASE | re.DOTALL)\n",
    "            sql = fallback.group(0) if fallback else text\n",
    "\n",
    "    sql = ' '.join(sql.strip().split())\n",
    "    return sql.rstrip(';') + ';'\n",
    "\n",
    "def setup_database(schema: str) -> sqlite3.Connection:\n",
    "    conn = sqlite3.connect(\":memory:\")\n",
    "    conn.executescript(schema)\n",
    "    conn.commit()\n",
    "    return conn\n",
    "\n",
    "def execute_sql_query(conn: sqlite3.Connection, sql_query: str) -> List[Dict]:\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql_query)\n",
    "    return cursor.fetchall()\n",
    "\n",
    "def check_execution_accuracy(schema: str, generated_sql: str, gold_sql: str) -> bool:\n",
    "    try:\n",
    "        conn = setup_database(schema)\n",
    "        res1 = execute_sql_query(conn, generated_sql)\n",
    "        res2 = execute_sql_query(conn, gold_sql)\n",
    "        conn.close()\n",
    "        return res1 == res2\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Evaluation\n",
    "def evaluate_model(model, tokenizer, samples: List[Dict]) -> Dict:\n",
    "    exact_matches = 0\n",
    "    execution_correct = 0\n",
    "    results = []\n",
    "\n",
    "    for ex in samples:\n",
    "        prompt = f\"### Instruction:\\nWrite only the SQL query that answers the question below, using the given database schema. Do not add explanations, examples, or comments.\\n\\n### Schema:\\n{ex['context']}\\n\\n### Question:\\n{ex['question']}\\n\\n### SQL:\\n\"\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=64,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_p=0.9,\n",
    "            )\n",
    "\n",
    "        decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        raw_generation = decoded[len(prompt):].strip()\n",
    "        #print(f\"\\n[RAW MODEL OUTPUT]:\\n{raw_generation}\\n\")\n",
    "\n",
    "        generated_sql = extract_sql(raw_generation)\n",
    "        gold_sql = ex['answer'].strip()\n",
    "\n",
    "        is_exact = generated_sql.lower() == gold_sql.lower()\n",
    "        is_exec_correct = check_execution_accuracy(ex['context'], generated_sql, gold_sql)\n",
    "\n",
    "        exact_matches += is_exact\n",
    "        execution_correct += is_exec_correct\n",
    "\n",
    "        results.append({\n",
    "            'question': ex['question'],\n",
    "            'schema': ex['context'],\n",
    "            'generated_sql': generated_sql,\n",
    "            'gold_sql': gold_sql,\n",
    "            'exact_match': is_exact,\n",
    "            'execution_correct': is_exec_correct\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        'exact_match_count': exact_matches,\n",
    "        'execution_correct_count': execution_correct,\n",
    "        'total_samples': len(samples),\n",
    "        'exact_match_rate': exact_matches / len(samples),\n",
    "        'execution_accuracy': execution_correct / len(samples),\n",
    "        'results': results\n",
    "    }\n",
    "\n",
    "# Plotting\n",
    "def plot_metrics(ft_results: Dict, base_results: Dict):\n",
    "    labels = ['Exact Match', 'Execution Accuracy']\n",
    "    finetuned = [ft_results['exact_match_rate'], ft_results['execution_accuracy']]\n",
    "    base = [base_results['exact_match_rate'], base_results['execution_accuracy']]\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    bars1 = ax.bar(x - width/2, finetuned, width, label='Fine-Tuned LLaMA 3')\n",
    "    bars2 = ax.bar(x + width/2, base, width, label='Base LLaMA 3')\n",
    "\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('Exact Match & Execution Accuracy (50 samples)')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.legend()\n",
    "    ax.bar_label(bars1, fmt='%.2f', padding=3)\n",
    "    ax.bar_label(bars2, fmt='%.2f', padding=3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main\n",
    "def main():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    dataset = load_dataset(\"b-mc2/sql-create-context\", split=\"train\")\n",
    "    split = dataset.train_test_split(test_size=100, seed=1399, shuffle=True)\n",
    "    val_data = split[\"test\"].shuffle(seed=1399)\n",
    "    samples = val_data.select(range(50))\n",
    "    #print(f\"Validation size: {len(samples)}\")\n",
    "\n",
    "    finetuned_model_path = \"./llama3-sql-lora/final-merged\"\n",
    "    base_model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "    print(\"\\n=== Loading Fine-Tuned LLaMA 3 Model ===\")\n",
    "    ft_tokenizer = AutoTokenizer.from_pretrained(finetuned_model_path, trust_remote_code=True)\n",
    "    ft_tokenizer.pad_token = ft_tokenizer.eos_token\n",
    "    ft_model = AutoModelForCausalLM.from_pretrained(\n",
    "        finetuned_model_path, device_map=\"auto\", torch_dtype=torch.bfloat16\n",
    "    ).eval()\n",
    "\n",
    "    print(\"\\n=== Loading Base LLaMA 3 Model ===\")\n",
    "    base_tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
    "    base_tokenizer.pad_token = base_tokenizer.eos_token\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_id, device_map=\"auto\", torch_dtype=torch.bfloat16\n",
    "    ).eval()\n",
    "\n",
    "    print(\"\\n=== Evaluating Fine-Tuned Model ===\")\n",
    "    ft_results = evaluate_model(ft_model, ft_tokenizer, samples)\n",
    "    print(f\"Exact Matches: {ft_results['exact_match_count']}/{ft_results['total_samples']} \"\n",
    "          f\"({ft_results['exact_match_rate']:.2%})\")\n",
    "    print(f\"Execution Accuracy: {ft_results['execution_correct_count']}/{ft_results['total_samples']} \"\n",
    "          f\"({ft_results['execution_accuracy']:.2%})\")\n",
    "\n",
    "    print(\"\\n=== Evaluating Base Model ===\")\n",
    "    base_results = evaluate_model(base_model, base_tokenizer, samples)\n",
    "    print(f\"Exact Matches: {base_results['exact_match_count']}/{base_results['total_samples']} \"\n",
    "          f\"({base_results['exact_match_rate']:.2%})\")\n",
    "    print(f\"Execution Accuracy: {base_results['execution_correct_count']}/{base_results['total_samples']} \"\n",
    "          f\"({base_results['execution_accuracy']:.2%})\")\n",
    "\n",
    "    # Plot metrics\n",
    "    plot_metrics(ft_results, base_results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
